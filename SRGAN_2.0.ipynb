{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict as edict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Here, we build a dictionary including the hyperparameters that we will use in training and testing. In all these models, we will use \"Adam\" as the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = edict()\n",
    "config.TRAIN = edict()\n",
    "config.VALID = edict()\n",
    "\n",
    "## some parameters for Adam\n",
    "config.TRAIN.batch_size = 4 # depends on GPU's memory, use 8 or 16 for faster training if allowed\n",
    "config.TRAIN.lr_init = 1e-4 # the initial learning rate\n",
    "config.TRAIN.beta1 = 0.9 # The exponential decay rate for the 1st moment estimates\n",
    "\n",
    "## parameters for initializing Generator\n",
    "config.TRAIN.n_epoch_init = 100 # use 100 for better performance\n",
    "    \n",
    "## parameters for adversarial learning (SRGAN)\n",
    "config.TRAIN.n_epoch = 1000 # use 2000 for better performance if allowed\n",
    "config.TRAIN.lr_decay = 0.1 # define the decay of learning rate here\n",
    "config.TRAIN.decay_every = int(config.TRAIN.n_epoch / 2) # define the frequency of learning rate decay here\n",
    "\n",
    "## training set location\n",
    "config.TRAIN.hr_img_path = 'DIV2K/Train_HR/'\n",
    "config.TRAIN.lr_img_path = 'DIV2K/Train_LR/'\n",
    "\n",
    "## test set location\n",
    "config.VALID.hr_img_path = 'DIV2K/Test_HR/'\n",
    "config.VALID.lr_img_path = 'DIV2K/Test_LR/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import skimage\n",
    "import numpy as np\n",
    "import scipy, multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "from tensorlayer.layers import (Input, Conv2d, BatchNorm2d, Elementwise, SubpixelConv2d, Flatten, Dense)\n",
    "from tensorlayer.models import Model\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models\n",
    "In this part, we define three functions of building models for the later need. And we apply the tensorlayer library to build all the models.\n",
    "- Generator for training\n",
    "- Generator for testing\n",
    "- Discriminator for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_G(input_shape):\n",
    "    w_init = tf.random_normal_initializer(stddev=0.02) # the initializer for weight matrix\n",
    "    g_init = tf.random_normal_initializer(1., 0.02) # initializer for initializing gamma in batch normalization\n",
    "\n",
    "    nin = Input(input_shape)\n",
    "    n = Conv2d(64, (3, 3), (1, 1), act=tf.nn.relu, padding='SAME', W_init=w_init)(nin)\n",
    "    temp = n\n",
    "\n",
    "    # B residual blocks\n",
    "    for i in range(16):\n",
    "        nn = Conv2d(64, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "        nn = BatchNorm2d(act=tf.nn.relu, gamma_init=g_init)(nn)\n",
    "        nn = Conv2d(64, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=None)(nn)\n",
    "        nn = BatchNorm2d(gamma_init=g_init)(nn)\n",
    "        nn = Elementwise(tf.add)([n, nn])\n",
    "        n = nn\n",
    "\n",
    "    n = Conv2d(64, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(gamma_init=g_init)(n)\n",
    "    n = Elementwise(tf.add)([n, temp])\n",
    "    # B residual blacks end\n",
    "\n",
    "    n = Conv2d(256, (3, 3), (1, 1), padding='SAME', W_init=w_init)(n)\n",
    "    n = SubpixelConv2d(scale=2, n_out_channels=None, act=tf.nn.relu)(n)\n",
    "\n",
    "    n = Conv2d(256, (3, 3), (1, 1), act=None, padding='SAME', W_init=w_init)(n)\n",
    "    n = SubpixelConv2d(scale=2, n_out_channels=None, act=tf.nn.relu)(n)\n",
    "\n",
    "    nn = Conv2d(3, (1, 1), (1, 1), act=tf.nn.tanh, padding='SAME', W_init=w_init)(n)\n",
    "    G = Model(inputs=nin, outputs=nn, name=\"generator\")\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Gval(input_shape):\n",
    "    w_init = tf.random_normal_initializer(stddev=0.02)\n",
    "    g_init = tf.random_normal_initializer(1., 0.02)\n",
    "\n",
    "    nin = Input(input_shape)\n",
    "    n = Conv2d(64, (3, 3), (1, 1), act=tf.nn.relu, padding='SAME', W_init=w_init)(nin)\n",
    "    temp = n\n",
    "\n",
    "    # B residual blocks\n",
    "    for i in range(16):\n",
    "        nn = Conv2d(64, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "        nn = BatchNorm2d(act=tf.nn.relu, gamma_init=g_init)(nn)\n",
    "        nn = Conv2d(64, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=None)(nn)\n",
    "        nn = BatchNorm2d(gamma_init=g_init)(nn)\n",
    "        nn = Elementwise(tf.add)([n, nn])\n",
    "        n = nn\n",
    "\n",
    "    n = Conv2d(64, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(gamma_init=g_init)(n)\n",
    "    n = Elementwise(tf.add)([n, temp])\n",
    "    # B residual blacks end\n",
    "\n",
    "    n = Conv2d(256, (3, 3), (1, 1), padding='SAME', W_init=w_init)(n)\n",
    "    n = SubpixelConv2d(scale=2, n_out_channels=None, act=tf.nn.relu)(n)\n",
    "\n",
    "    n = Conv2d(256, (3, 3), (1, 1), act=None, padding='SAME', W_init=w_init)(n)\n",
    "    n = SubpixelConv2d(scale=2, n_out_channels=None, act=tf.nn.relu)(n)\n",
    "\n",
    "    nn = Conv2d(3, (1, 1), (1, 1), act=tf.nn.tanh, padding='SAME', W_init=w_init)(n)\n",
    "    Gval = Model(inputs=nin, outputs=nn, name=\"generator_val0\")\n",
    "    return Gval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_D(input_shape):\n",
    "    w_init = tf.random_normal_initializer(stddev=0.02) # the initializer for weight matrix\n",
    "    gamma_init = tf.random_normal_initializer(1., 0.02) # initializer for initializing gamma in batch normalization\n",
    "    df_dim = 64\n",
    "    lrelu = lambda x: tl.act.lrelu(x, 0.2)\n",
    "\n",
    "    nin = Input(input_shape)\n",
    "    n = Conv2d(df_dim, (4, 4), (2, 2), act=lrelu, padding='SAME', W_init=w_init)(nin)\n",
    "\n",
    "    n = Conv2d(df_dim * 2, (4, 4), (2, 2), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n",
    "    n = Conv2d(df_dim * 4, (4, 4), (2, 2), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n",
    "    n = Conv2d(df_dim * 8, (4, 4), (2, 2), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n",
    "    n = Conv2d(df_dim * 16, (4, 4), (2, 2), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n",
    "    n = Conv2d(df_dim * 32, (4, 4), (2, 2), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n",
    "    n = Conv2d(df_dim * 16, (1, 1), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n",
    "    n = Conv2d(df_dim * 8, (1, 1), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    nn = BatchNorm2d(gamma_init=gamma_init)(n)\n",
    "\n",
    "    n = Conv2d(df_dim * 2, (1, 1), (1, 1), padding='SAME', W_init=w_init, b_init=None)(nn)\n",
    "    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n",
    "    n = Conv2d(df_dim * 2, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n",
    "    n = Conv2d(df_dim * 8, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(gamma_init=gamma_init)(n)\n",
    "    n = Elementwise(combine_fn=tf.add, act=lrelu)([n, nn])\n",
    "\n",
    "    n = Flatten()(n)\n",
    "    no = Dense(n_units=1, W_init=w_init)(n)\n",
    "    D = Model(inputs=nin, outputs=no, name=\"discriminator\")\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "Below is the main traininig process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###====================== HYPER-PARAMETERS ===========================###\n",
    "\n",
    "## Here we load the hyperparameters defined above from the dictionary\n",
    "\n",
    "## Adam\n",
    "batch_size = config.TRAIN.batch_size  # use 8 if your GPU memory is small, and change [4, 4] in tl.vis.save_images to [2, 4]\n",
    "lr_init = config.TRAIN.lr_init\n",
    "beta1 = config.TRAIN.beta1\n",
    "\n",
    "## initialize G\n",
    "n_epoch_init = config.TRAIN.n_epoch_init\n",
    "\n",
    "## adversarial learning (SRGAN)\n",
    "n_epoch = config.TRAIN.n_epoch\n",
    "lr_decay = config.TRAIN.lr_decay\n",
    "decay_every = config.TRAIN.decay_every\n",
    "shuffle_buffer_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] [!] samples exists ...\n",
      "[TL] [!] models exists ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create folders to save result images and trained models\n",
    "save_dir = \"samples\"\n",
    "tl.files.exists_or_mkdir(save_dir)\n",
    "checkpoint_dir = \"models\"\n",
    "tl.files.exists_or_mkdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] read 32 from DIV2K/Train_HR/\n",
      "[TL] read 64 from DIV2K/Train_HR/\n",
      "[TL] read 96 from DIV2K/Train_HR/\n",
      "[TL] read 128 from DIV2K/Train_HR/\n",
      "[TL] read 160 from DIV2K/Train_HR/\n",
      "[TL] read 192 from DIV2K/Train_HR/\n",
      "[TL] read 224 from DIV2K/Train_HR/\n",
      "[TL] read 256 from DIV2K/Train_HR/\n",
      "[TL] read 288 from DIV2K/Train_HR/\n",
      "[TL] read 320 from DIV2K/Train_HR/\n",
      "[TL] read 352 from DIV2K/Train_HR/\n",
      "[TL] read 384 from DIV2K/Train_HR/\n",
      "[TL] read 416 from DIV2K/Train_HR/\n",
      "[TL] read 448 from DIV2K/Train_HR/\n",
      "[TL] read 480 from DIV2K/Train_HR/\n",
      "[TL] read 512 from DIV2K/Train_HR/\n",
      "[TL] read 544 from DIV2K/Train_HR/\n",
      "[TL] read 576 from DIV2K/Train_HR/\n",
      "[TL] read 608 from DIV2K/Train_HR/\n",
      "[TL] read 640 from DIV2K/Train_HR/\n",
      "[TL] read 672 from DIV2K/Train_HR/\n",
      "[TL] read 704 from DIV2K/Train_HR/\n",
      "[TL] read 736 from DIV2K/Train_HR/\n",
      "[TL] read 768 from DIV2K/Train_HR/\n",
      "[TL] read 800 from DIV2K/Train_HR/\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "train_hr_img_list = sorted(tl.files.load_file_list(path=config.TRAIN.hr_img_path, regx='.*.png', printable=False))\n",
    "train_hr_imgs = tl.vis.read_images(train_hr_img_list, path=config.TRAIN.hr_img_path, n_threads=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_train():\n",
    "    for img in train_hr_imgs:\n",
    "        yield img\n",
    "def _map_fn_train(img):\n",
    "    hr_patch = tf.image.random_crop(img, [384, 384, 3])\n",
    "    hr_patch = hr_patch / (255. / 2.)\n",
    "    hr_patch = hr_patch - 1.\n",
    "    hr_patch = tf.image.random_flip_left_right(hr_patch)\n",
    "    lr_patch = tf.image.resize(hr_patch, size=[96, 96])\n",
    "    return lr_patch, hr_patch\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(generator_train, output_types=(tf.float32))\n",
    "train_ds = train_ds.map(_map_fn_train, num_parallel_calls=multiprocessing.cpu_count())\n",
    "    # train_ds = train_ds.repeat(n_epoch_init + n_epoch)\n",
    "train_ds = train_ds.shuffle(shuffle_buffer_size)\n",
    "train_ds = train_ds.prefetch(buffer_size=2)\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "    # value = train_ds.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] Input  _inputlayer_1: (4, 96, 96, 3)\n",
      "[TL] Conv2d conv2d_1: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2d_2: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_1: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_3: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_2: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_1: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_4: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_3: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_5: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_4: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_2: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_6: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_5: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_7: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_6: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_3: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_8: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_7: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_9: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_8: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_4: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_10: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_9: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_11: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_10: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_5: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_12: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_11: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_13: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_12: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_6: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_14: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_13: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_15: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_14: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_7: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_16: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_15: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_17: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_16: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_8: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_18: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_17: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_19: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_18: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_9: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_20: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_19: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_21: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_20: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_10: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_22: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_21: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_23: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_22: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_11: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_24: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_23: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_25: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_24: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_12: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_26: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_25: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_27: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_26: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_13: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_28: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_27: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_29: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_28: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_14: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_30: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_29: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_31: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_30: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_15: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_32: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_31: decay: 0.900000 epsilon: 0.000010 act: relu is_train: False\n",
      "[TL] Conv2d conv2d_33: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_32: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_16: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_34: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_33: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_17: fn: add act: No Activation\n",
      "[TL] Conv2d conv2d_35: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] SubpixelConv2d  subpixelconv2d_1: scale: 2 act: relu\n",
      "[TL] Conv2d conv2d_36: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] SubpixelConv2d  subpixelconv2d_2: scale: 2 act: relu\n",
      "[TL] Conv2d conv2d_37: n_filter: 3 filter_size: (1, 1) strides: (1, 1) pad: SAME act: tanh\n",
      "[TL] Input  _inputlayer_2: (4, 384, 384, 3)\n",
      "[TL] Conv2d conv2d_38: n_filter: 64 filter_size: (4, 4) strides: (2, 2) pad: SAME act: <lambda>\n",
      "[TL] Conv2d conv2d_39: n_filter: 128 filter_size: (4, 4) strides: (2, 2) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_34: decay: 0.900000 epsilon: 0.000010 act: <lambda> is_train: False\n",
      "[TL] Conv2d conv2d_40: n_filter: 256 filter_size: (4, 4) strides: (2, 2) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_35: decay: 0.900000 epsilon: 0.000010 act: <lambda> is_train: False\n",
      "[TL] Conv2d conv2d_41: n_filter: 512 filter_size: (4, 4) strides: (2, 2) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_36: decay: 0.900000 epsilon: 0.000010 act: <lambda> is_train: False\n",
      "[TL] Conv2d conv2d_42: n_filter: 1024 filter_size: (4, 4) strides: (2, 2) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_37: decay: 0.900000 epsilon: 0.000010 act: <lambda> is_train: False\n",
      "[TL] Conv2d conv2d_43: n_filter: 2048 filter_size: (4, 4) strides: (2, 2) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_38: decay: 0.900000 epsilon: 0.000010 act: <lambda> is_train: False\n",
      "[TL] Conv2d conv2d_44: n_filter: 1024 filter_size: (1, 1) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_39: decay: 0.900000 epsilon: 0.000010 act: <lambda> is_train: False\n",
      "[TL] Conv2d conv2d_45: n_filter: 512 filter_size: (1, 1) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_40: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Conv2d conv2d_46: n_filter: 128 filter_size: (1, 1) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_41: decay: 0.900000 epsilon: 0.000010 act: <lambda> is_train: False\n",
      "[TL] Conv2d conv2d_47: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_42: decay: 0.900000 epsilon: 0.000010 act: <lambda> is_train: False\n",
      "[TL] Conv2d conv2d_48: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: No Activation\n",
      "[TL] BatchNorm batchnorm2d_43: decay: 0.900000 epsilon: 0.000010 act: No Activation is_train: False\n",
      "[TL] Elementwise elementwise_18: fn: add act: <lambda>\n",
      "[TL] Flatten flatten_1:\n",
      "[TL] Dense  dense_1: 1 No Activation\n",
      "[TL] Input  _inputlayer_3: [None, 224, 224, 3]\n",
      "[TL] Lambda  scale: func: <function VGG_static.<locals>.<lambda> at 0x7f53100d9830>, len_weights: 0\n",
      "[TL] Conv2d conv1_1: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv1_2: n_filter: 64 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d pool1: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "[TL] Conv2d conv2_1: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv2_2: n_filter: 128 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d pool2: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "[TL] Conv2d conv3_1: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv3_2: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv3_3: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv3_4: n_filter: 256 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d pool3: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "[TL] Conv2d conv4_1: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv4_2: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv4_3: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] Conv2d conv4_4: n_filter: 512 filter_size: (3, 3) strides: (1, 1) pad: SAME act: relu\n",
      "[TL] MaxPool2d pool4: filter_size: (2, 2) strides: (2, 2) padding: SAME\n",
      "[TL] LayerList layerlist_1 including layers [conv1_1, conv1_2, pool1, conv2_1, conv2_2, pool2, conv3_1, conv3_2, conv3_3, conv3_4, pool3, conv4_1, conv4_2, conv4_3, conv4_4, pool4]\n",
      "[TL] Restore pre-trained weights\n",
      "[TL]   Loading (3, 3, 3, 64) in conv1_1\n",
      "[TL]   Loading (64,) in conv1_1\n",
      "[TL]   Loading (3, 3, 64, 64) in conv1_2\n",
      "[TL]   Loading (64,) in conv1_2\n",
      "[TL]   Loading (3, 3, 64, 128) in conv2_1\n",
      "[TL]   Loading (128,) in conv2_1\n",
      "[TL]   Loading (3, 3, 128, 128) in conv2_2\n",
      "[TL]   Loading (128,) in conv2_2\n",
      "[TL]   Loading (3, 3, 128, 256) in conv3_1\n",
      "[TL]   Loading (256,) in conv3_1\n",
      "[TL]   Loading (3, 3, 256, 256) in conv3_2\n",
      "[TL]   Loading (256,) in conv3_2\n",
      "[TL]   Loading (3, 3, 256, 256) in conv3_3\n",
      "[TL]   Loading (256,) in conv3_3\n",
      "[TL]   Loading (3, 3, 256, 256) in conv3_4\n",
      "[TL]   Loading (256,) in conv3_4\n",
      "[TL]   Loading (3, 3, 256, 512) in conv4_1\n",
      "[TL]   Loading (512,) in conv4_1\n",
      "[TL]   Loading (3, 3, 512, 512) in conv4_2\n",
      "[TL]   Loading (512,) in conv4_2\n",
      "[TL]   Loading (3, 3, 512, 512) in conv4_3\n",
      "[TL]   Loading (512,) in conv4_3\n",
      "[TL]   Loading (3, 3, 512, 512) in conv4_4\n",
      "[TL]   Loading (512,) in conv4_4\n"
     ]
    }
   ],
   "source": [
    "G = get_G((batch_size, 96, 96, 3))\n",
    "D = get_D((batch_size, 384, 384, 3))\n",
    "VGG = tl.models.vgg19(pretrained=True, end_with='pool4', mode='static')\n",
    "\n",
    "lr_v = tf.Variable(lr_init)\n",
    "g_optimizer_init = tf.optimizers.Adam(lr_v, beta_1=beta1)\n",
    "g_optimizer = tf.optimizers.Adam(lr_v, beta_1=beta1)\n",
    "d_optimizer = tf.optimizers.Adam(lr_v, beta_1=beta1)\n",
    "\n",
    "G.train()\n",
    "D.train()\n",
    "VGG.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize learning (G)\n",
    "n_step_epoch = round(n_epoch_init // batch_size)\n",
    "for epoch in range(n_epoch_init):\n",
    "    for step, (lr_patchs, hr_patchs) in enumerate(train_ds):\n",
    "        if lr_patchs.shape[0] != batch_size: # if the remaining data in this epoch < batch_size\n",
    "            break\n",
    "        step_time = time.time()\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_hr_patchs = G(lr_patchs)\n",
    "            mse_loss = tl.cost.mean_squared_error(fake_hr_patchs, hr_patchs, is_mean=True)\n",
    "        grad = tape.gradient(mse_loss, G.trainable_weights)\n",
    "        g_optimizer_init.apply_gradients(zip(grad, G.trainable_weights))\n",
    "        print(\"Epoch: [{}/{}] step: [{}/{}] time: {:.3f}s, mse: {:.3f} \".format(\n",
    "            epoch, n_epoch_init, step, n_step_epoch, time.time() - step_time, mse_loss))\n",
    "    if (epoch != 0) and (epoch % 10 == 0):\n",
    "        tl.vis.save_images(fake_hr_patchs.numpy(), [2, 4], os.path.join(save_dir, 'train_g_init_{}.png'.format(epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## adversarial learning (G, D)\n",
    "n_step_epoch = round(n_epoch // batch_size)\n",
    "for epoch in range(n_epoch):\n",
    "    for step, (lr_patchs, hr_patchs) in enumerate(train_ds):\n",
    "        if lr_patchs.shape[0] != batch_size: # if the remaining data in this epoch < batch_size\n",
    "            break\n",
    "        step_time = time.time()\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            fake_patchs = G(lr_patchs)\n",
    "            logits_fake = D(fake_patchs)\n",
    "            logits_real = D(hr_patchs)\n",
    "            feature_fake = VGG((fake_patchs+1)/2.) # the pre-trained VGG uses the input range of [0, 1]\n",
    "            feature_real = VGG((hr_patchs+1)/2.)\n",
    "            d_loss1 = tl.cost.sigmoid_cross_entropy(logits_real, tf.ones_like(logits_real))\n",
    "            d_loss2 = tl.cost.sigmoid_cross_entropy(logits_fake, tf.zeros_like(logits_fake))\n",
    "            d_loss = d_loss1 + d_loss2\n",
    "            g_gan_loss = 1e-3 * tl.cost.sigmoid_cross_entropy(logits_fake, tf.ones_like(logits_fake))\n",
    "            mse_loss = tl.cost.mean_squared_error(fake_patchs, hr_patchs, is_mean=True)\n",
    "            vgg_loss = 2e-6 * tl.cost.mean_squared_error(feature_fake, feature_real, is_mean=True)\n",
    "            g_loss = mse_loss + vgg_loss + g_gan_loss\n",
    "        grad = tape.gradient(g_loss, G.trainable_weights)\n",
    "        g_optimizer.apply_gradients(zip(grad, G.trainable_weights))\n",
    "        grad = tape.gradient(d_loss, D.trainable_weights)\n",
    "        d_optimizer.apply_gradients(zip(grad, D.trainable_weights))\n",
    "        print(\"Epoch: [{}/{}] step: [{}/{}] time: {:.3f}s, g_loss(mse:{:.3f}, vgg:{:.3f}, adv:{:.3f}) d_loss: {:.3f}\".format(\n",
    "            epoch, n_epoch_init, step, n_step_epoch, time.time() - step_time, mse_loss, vgg_loss, g_gan_loss, d_loss))\n",
    "\n",
    "    # update the learning rate\n",
    "    if epoch != 0 and (epoch % decay_every == 0):\n",
    "        new_lr_decay = lr_decay**(epoch // decay_every)\n",
    "        lr_v.assign(lr_init * new_lr_decay)\n",
    "        log = \" ** new learning rate: %f (for GAN)\" % (lr_init * new_lr_decay)\n",
    "        print(log)\n",
    "\n",
    "    if (epoch != 0) and (epoch % 10 == 0):\n",
    "        tl.vis.save_images(fake_patchs.numpy(), [2, 4], os.path.join(save_dir, 'train_g_{}.png'.format(epoch)))\n",
    "        G.save_weights(os.path.join(checkpoint_dir, 'g.h5'))\n",
    "        D.save_weights(os.path.join(checkpoint_dir, 'd.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###====================== Loading Test Data ===========================###\n",
    "valid_hr_img_list = sorted(tl.files.load_file_list(path=config.VALID.hr_img_path, regx='.*.png', printable=False))\n",
    "valid_lr_img_list = sorted(tl.files.load_file_list(path=config.VALID.lr_img_path, regx='.*.png', printable=False))\n",
    "valid_lr_imgs = tl.vis.read_images(valid_lr_img_list, path=config.VALID.lr_img_path, n_threads=32)\n",
    "valid_hr_imgs = tl.vis.read_images(valid_hr_img_list, path=config.VALID.hr_img_path, n_threads=32)\n",
    "\n",
    "###========================== DEFINE MODEL ============================###\n",
    "imid = 64  # 0: Penguin  81: Butterfly  53: Bird  64: Castle\n",
    "valid_lr_img = valid_lr_imgs[imid]\n",
    "valid_hr_img = valid_hr_imgs[imid]\n",
    "# valid_lr_img = get_imgs_fn('test.png', 'data2017/')  # if you want to test your own image\n",
    "valid_lr_img = (valid_lr_img / 127.5) - 1  # rescale to [-1, 1]\n",
    "# print(valid_lr_img.min(), valid_lr_img.max())\n",
    "\n",
    "G2 = get_Gval([1, None, None, 3])\n",
    "G2.load_weights(os.path.join(checkpoint_dir, 'g.h5'))\n",
    "G2.eval()\n",
    "\n",
    "valid_lr_img = np.asarray(valid_lr_img, dtype=np.float32)\n",
    "valid_lr_img = valid_lr_img[np.newaxis,:,:,:]\n",
    "size = [valid_lr_img.shape[1], valid_lr_img.shape[2]]\n",
    "\n",
    "out = G2(valid_lr_img).numpy()\n",
    "\n",
    "print(\"LR size: %s /  generated HR size: %s\" % (size, out.shape))  # LR size: (339, 510, 3) /  gen HR size: (1, 1356, 2040, 3)\n",
    "print(\"[*] save images\")\n",
    "tl.vis.save_image(out[0], os.path.join(save_dir, 'valid_gen.png'))\n",
    "tl.vis.save_image(valid_lr_img[0], os.path.join(save_dir, 'valid_lr.png'))\n",
    "tl.vis.save_image(valid_hr_img, os.path.join(save_dir, 'valid_hr.png'))\n",
    "\n",
    "out_bicu  = skimage.transform.resize(valid_lr_img[0], [size[0] * 4, size[1] * 4], order=1)\n",
    "\n",
    "tl.vis.save_image(out_bicu, os.path.join(save_dir, 'valid_bicubic.png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37-tf2",
   "language": "python",
   "name": "py37-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
