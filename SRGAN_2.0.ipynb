{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict as edict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Here, we build a dictionary including the hyperparameters that we will use in training and testing. In all these models, we will use \"Adam\" as the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = edict()\n",
    "config.TRAIN = edict()\n",
    "config.VALID = edict()\n",
    "\n",
    "## some parameters for Adam\n",
    "config.TRAIN.batch_size = 4 # depends on GPU's memory, use 8 or 16 for faster training if allowed\n",
    "config.TRAIN.lr_init = 1e-4 # the initial learning rate\n",
    "config.TRAIN.beta1 = 0.9 # The exponential decay rate for the 1st moment estimates\n",
    "\n",
    "## parameters for initializing Generator\n",
    "config.TRAIN.n_epoch_init = 50 # use 100 for better performance\n",
    "    \n",
    "## parameters for adversarial learning (SRGAN)\n",
    "config.TRAIN.n_epoch = 50 # use 2000 for better performance if allowed\n",
    "config.TRAIN.lr_decay = 0.1 # define the decay of learning rate here\n",
    "config.TRAIN.decay_every = int(config.TRAIN.n_epoch / 2) # define the frequency of learning rate decay here\n",
    "\n",
    "## training set location\n",
    "config.TRAIN.hr_img_path = '../srgan/DIV2K_train_HR/'\n",
    "config.TRAIN.lr_img_path = '../srgan/DIV2K_train_LR_bicubic/X4/'\n",
    "\n",
    "## test set location\n",
    "config.VALID.hr_img_path = '../srgan/DIV2K_valid_HR/'\n",
    "config.VALID.lr_img_path = '../srgan/DIV2K_valid_LR_bicubic/X4/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import skimage\n",
    "import numpy as np\n",
    "import scipy, multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "from tensorlayer.layers import (Input, Conv2d, BatchNorm2d, Elementwise, SubpixelConv2d, Flatten, Dense)\n",
    "from tensorlayer.models import Model\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models\n",
    "In this part, we define three functions of building models for the later need. And we apply the tensorlayer library to build all the models.\n",
    "- Generator for training\n",
    "- Generator for testing\n",
    "- Discriminator for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_G(input_shape):\n",
    "    w_init = tf.random_normal_initializer(stddev=0.02) # the initializer for weight matrix\n",
    "    g_init = tf.random_normal_initializer(1., 0.02) # initializer for initializing gamma in batch normalization\n",
    "\n",
    "    nin = Input(input_shape)\n",
    "    n = Conv2d(64, (3, 3), (1, 1), act=tf.nn.relu, padding='SAME', W_init=w_init)(nin)\n",
    "    temp = n\n",
    "\n",
    "    # B residual blocks\n",
    "    for i in range(16):\n",
    "        nn = Conv2d(64, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "        nn = BatchNorm2d(act=tf.nn.relu, gamma_init=g_init)(nn)\n",
    "        nn = Conv2d(64, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=None)(nn)\n",
    "        nn = BatchNorm2d(gamma_init=g_init)(nn)\n",
    "        nn = Elementwise(tf.add)([n, nn])\n",
    "        n = nn\n",
    "\n",
    "    n = Conv2d(64, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(gamma_init=g_init)(n)\n",
    "    n = Elementwise(tf.add)([n, temp])\n",
    "    # B residual blacks end\n",
    "\n",
    "    n = Conv2d(256, (3, 3), (1, 1), padding='SAME', W_init=w_init)(n)\n",
    "    n = SubpixelConv2d(scale=2, n_out_channels=None, act=tf.nn.relu)(n)\n",
    "\n",
    "    n = Conv2d(256, (3, 3), (1, 1), act=None, padding='SAME', W_init=w_init)(n)\n",
    "    n = SubpixelConv2d(scale=2, n_out_channels=None, act=tf.nn.relu)(n)\n",
    "\n",
    "    nn = Conv2d(3, (1, 1), (1, 1), act=tf.nn.tanh, padding='SAME', W_init=w_init)(n)\n",
    "    G = Model(inputs=nin, outputs=nn, name=\"generator\")\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Gval(input_shape):\n",
    "    w_init = tf.random_normal_initializer(stddev=0.02)\n",
    "    g_init = tf.random_normal_initializer(1., 0.02)\n",
    "\n",
    "    nin = Input(input_shape)\n",
    "    n = Conv2d(64, (3, 3), (1, 1), act=tf.nn.relu, padding='SAME', W_init=w_init)(nin)\n",
    "    temp = n\n",
    "\n",
    "    # B residual blocks\n",
    "    for i in range(16):\n",
    "        nn = Conv2d(64, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "        nn = BatchNorm2d(act=tf.nn.relu, gamma_init=g_init)(nn)\n",
    "        nn = Conv2d(64, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=None)(nn)\n",
    "        nn = BatchNorm2d(gamma_init=g_init)(nn)\n",
    "        nn = Elementwise(tf.add)([n, nn])\n",
    "        n = nn\n",
    "\n",
    "    n = Conv2d(64, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(gamma_init=g_init)(n)\n",
    "    n = Elementwise(tf.add)([n, temp])\n",
    "    # B residual blacks end\n",
    "\n",
    "    n = Conv2d(256, (3, 3), (1, 1), padding='SAME', W_init=w_init)(n)\n",
    "    n = SubpixelConv2d(scale=2, n_out_channels=None, act=tf.nn.relu)(n)\n",
    "\n",
    "    n = Conv2d(256, (3, 3), (1, 1), act=None, padding='SAME', W_init=w_init)(n)\n",
    "    n = SubpixelConv2d(scale=2, n_out_channels=None, act=tf.nn.relu)(n)\n",
    "\n",
    "    nn = Conv2d(3, (1, 1), (1, 1), act=tf.nn.tanh, padding='SAME', W_init=w_init)(n)\n",
    "    Gval = Model(inputs=nin, outputs=nn)\n",
    "    return Gval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_D(input_shape):\n",
    "    w_init = tf.random_normal_initializer(stddev=0.02) # the initializer for weight matrix\n",
    "    gamma_init = tf.random_normal_initializer(1., 0.02) # initializer for initializing gamma in batch normalization\n",
    "    df_dim = 64\n",
    "    lrelu = lambda x: tl.act.lrelu(x, 0.2)\n",
    "\n",
    "    nin = Input(input_shape)\n",
    "    n = Conv2d(df_dim, (4, 4), (2, 2), act=lrelu, padding='SAME', W_init=w_init)(nin)\n",
    "\n",
    "    n = Conv2d(df_dim * 2, (4, 4), (2, 2), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n",
    "    n = Conv2d(df_dim * 4, (4, 4), (2, 2), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n",
    "    n = Conv2d(df_dim * 8, (4, 4), (2, 2), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n",
    "    n = Conv2d(df_dim * 16, (4, 4), (2, 2), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n",
    "    n = Conv2d(df_dim * 32, (4, 4), (2, 2), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n",
    "    n = Conv2d(df_dim * 16, (1, 1), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n",
    "    n = Conv2d(df_dim * 8, (1, 1), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    nn = BatchNorm2d(gamma_init=gamma_init)(n)\n",
    "\n",
    "    n = Conv2d(df_dim * 2, (1, 1), (1, 1), padding='SAME', W_init=w_init, b_init=None)(nn)\n",
    "    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n",
    "    n = Conv2d(df_dim * 2, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(act=lrelu, gamma_init=gamma_init)(n)\n",
    "    n = Conv2d(df_dim * 8, (3, 3), (1, 1), padding='SAME', W_init=w_init, b_init=None)(n)\n",
    "    n = BatchNorm2d(gamma_init=gamma_init)(n)\n",
    "    n = Elementwise(combine_fn=tf.add, act=lrelu)([n, nn])\n",
    "\n",
    "    n = Flatten()(n)\n",
    "    no = Dense(n_units=1, W_init=w_init)(n)\n",
    "    D = Model(inputs=nin, outputs=no, name=\"discriminator\")\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "Below is the main traininig process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###====================== HYPER-PARAMETERS ===========================###\n",
    "\n",
    "## Here we load the hyperparameters defined above from the dictionary\n",
    "\n",
    "## Adam\n",
    "batch_size = config.TRAIN.batch_size  # use 8 if your GPU memory is small, and change [4, 4] in tl.vis.save_images to [2, 4]\n",
    "lr_init = config.TRAIN.lr_init\n",
    "beta1 = config.TRAIN.beta1\n",
    "\n",
    "## initialize G\n",
    "n_epoch_init = config.TRAIN.n_epoch_init\n",
    "\n",
    "## adversarial learning (SRGAN)\n",
    "n_epoch = config.TRAIN.n_epoch\n",
    "lr_decay = config.TRAIN.lr_decay\n",
    "decay_every = config.TRAIN.decay_every\n",
    "shuffle_buffer_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folders to save result images and trained models\n",
    "save_dir = \"samples\"\n",
    "tl.files.exists_or_mkdir(save_dir)\n",
    "checkpoint_dir = \"models\"\n",
    "tl.files.exists_or_mkdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "train_hr_img_list = sorted(tl.files.load_file_list(path=config.TRAIN.hr_img_path, regx='.*.png', printable=False))\n",
    "train_hr_imgs = tl.vis.read_images(train_hr_img_list, path=config.TRAIN.hr_img_path, n_threads=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_train():\n",
    "    for img in train_hr_imgs:\n",
    "        yield img\n",
    "def _map_fn_train(img):\n",
    "    hr_patch = tf.image.random_crop(img, [384, 384, 3])\n",
    "    hr_patch = hr_patch / (255. / 2.)\n",
    "    hr_patch = hr_patch - 1.\n",
    "    hr_patch = tf.image.random_flip_left_right(hr_patch)\n",
    "    lr_patch = tf.image.resize(hr_patch, size=[96, 96])\n",
    "    return lr_patch, hr_patch\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(generator_train, output_types=(tf.float32))\n",
    "train_ds = train_ds.map(_map_fn_train, num_parallel_calls=multiprocessing.cpu_count())\n",
    "    # train_ds = train_ds.repeat(n_epoch_init + n_epoch)\n",
    "train_ds = train_ds.shuffle(shuffle_buffer_size)\n",
    "train_ds = train_ds.prefetch(buffer_size=2)\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "    # value = train_ds.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = get_G((batch_size, 96, 96, 3))\n",
    "D = get_D((batch_size, 384, 384, 3))\n",
    "VGG = tl.models.vgg19(pretrained=True, end_with='pool4', mode='static')\n",
    "\n",
    "lr_v = tf.Variable(lr_init)\n",
    "g_optimizer_init = tf.optimizers.Adam(lr_v, beta_1=beta1)\n",
    "g_optimizer = tf.optimizers.Adam(lr_v, beta_1=beta1)\n",
    "d_optimizer = tf.optimizers.Adam(lr_v, beta_1=beta1)\n",
    "\n",
    "G.train()\n",
    "D.train()\n",
    "VGG.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## initialize learning (G)\n",
    "n_step_epoch = round(n_epoch_init // batch_size)\n",
    "for epoch in range(n_epoch_init):\n",
    "    for step, (lr_patchs, hr_patchs) in enumerate(train_ds):\n",
    "        if lr_patchs.shape[0] != batch_size: # if the remaining data in this epoch < batch_size\n",
    "            break\n",
    "        step_time = time.time()\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_hr_patchs = G(lr_patchs)\n",
    "            mse_loss = tl.cost.mean_squared_error(fake_hr_patchs, hr_patchs, is_mean=True)\n",
    "        grad = tape.gradient(mse_loss, G.trainable_weights)\n",
    "        g_optimizer_init.apply_gradients(zip(grad, G.trainable_weights))\n",
    "        print(\"Epoch: [{}/{}] step: [{}/{}] time: {:.3f}s, mse: {:.3f} \".format(\n",
    "            epoch, n_epoch_init, step, n_step_epoch, time.time() - step_time, mse_loss))\n",
    "    if (epoch != 0) and (epoch % 10 == 0):\n",
    "        tl.vis.save_images(fake_hr_patchs.numpy(), [2, 4], os.path.join(save_dir, 'train_g_init_{}.png'.format(epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## adversarial learning (G, D)\n",
    "n_step_epoch = round(n_epoch // batch_size)\n",
    "writer = tf.summary.create_file_writer('./log/'+ 'd_loss&g_loss')\n",
    "for epoch in range(n_epoch):\n",
    "    for step, (lr_patchs, hr_patchs) in enumerate(train_ds):\n",
    "        if lr_patchs.shape[0] != batch_size: # if the remaining data in this epoch < batch_size\n",
    "            break\n",
    "        step_time = time.time()\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            fake_patchs = G(lr_patchs)\n",
    "            logits_fake = D(fake_patchs)\n",
    "            logits_real = D(hr_patchs)\n",
    "            feature_fake = VGG((fake_patchs+1)/2.) # the pre-trained VGG uses the input range of [0, 1]\n",
    "            feature_real = VGG((hr_patchs+1)/2.)\n",
    "            d_loss1 = tl.cost.sigmoid_cross_entropy(logits_real, tf.ones_like(logits_real))\n",
    "            d_loss2 = tl.cost.sigmoid_cross_entropy(logits_fake, tf.zeros_like(logits_fake))\n",
    "            d_loss = d_loss1 + d_loss2\n",
    "            g_gan_loss = 1e-3 * tl.cost.sigmoid_cross_entropy(logits_fake, tf.ones_like(logits_fake))\n",
    "            mse_loss = tl.cost.mean_squared_error(fake_patchs, hr_patchs, is_mean=True)\n",
    "            vgg_loss = 2e-6 * tl.cost.mean_squared_error(feature_fake, feature_real, is_mean=True)\n",
    "            g_loss = mse_loss + vgg_loss + g_gan_loss\n",
    "\n",
    "            if epoch >0:\n",
    "                with writer.as_default():\n",
    "                    tf.summary.scalar('d_loss', d_loss, step=epoch+1)\n",
    "                    tf.summary.scalar('g_loss', g_loss, step=epoch+1)\n",
    "\n",
    "        grad = tape.gradient(g_loss, G.trainable_weights)\n",
    "        g_optimizer.apply_gradients(zip(grad, G.trainable_weights))\n",
    "        grad = tape.gradient(d_loss, D.trainable_weights)\n",
    "        d_optimizer.apply_gradients(zip(grad, D.trainable_weights))\n",
    "        print(\"Epoch: [{}/{}] step: [{}/{}] time: {:.3f}s, g_loss(mse:{:.3f}, vgg:{:.3f}, adv:{:.3f}) d_loss: {:.3f}\".format(\n",
    "            epoch, n_epoch_init, step, n_step_epoch, time.time() - step_time, mse_loss, vgg_loss, g_gan_loss, d_loss))\n",
    "\n",
    "    # update the learning rate\n",
    "    if epoch != 0 and (epoch % decay_every == 0):\n",
    "        new_lr_decay = lr_decay**(epoch // decay_every)\n",
    "        lr_v.assign(lr_init * new_lr_decay)\n",
    "        log = \" ** new learning rate: %f (for GAN)\" % (lr_init * new_lr_decay)\n",
    "        print(log)\n",
    "\n",
    "    if (epoch != 0) and (epoch % 10 == 0):\n",
    "        tl.vis.save_images(fake_patchs.numpy(), [2, 4], os.path.join(save_dir, 'train_g_{}.png'.format(epoch)))\n",
    "        G.save_weights(os.path.join(checkpoint_dir, 'g.h5'))\n",
    "        D.save_weights(os.path.join(checkpoint_dir, 'd.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###====================== Loading Test Data ===========================###\n",
    "valid_hr_img_list = sorted(tl.files.load_file_list(path=config.VALID.hr_img_path, regx='.*.png', printable=False))\n",
    "valid_lr_img_list = sorted(tl.files.load_file_list(path=config.VALID.lr_img_path, regx='.*.png', printable=False))\n",
    "valid_lr_imgs = tl.vis.read_images(valid_lr_img_list, path=config.VALID.lr_img_path, n_threads=32)\n",
    "valid_hr_imgs = tl.vis.read_images(valid_hr_img_list, path=config.VALID.hr_img_path, n_threads=32)\n",
    "\n",
    "###========================== DEFINE MODEL ============================###\n",
    "imid = 0  # 0: Penguin  81: Butterfly  53: Bird  64: Castle\n",
    "valid_lr_img = valid_lr_imgs[imid]\n",
    "valid_hr_img = valid_hr_imgs[imid]\n",
    "# valid_lr_img = get_imgs_fn('test.png', 'data2017/')  # if you want to test your own image\n",
    "valid_lr_img = (valid_lr_img / 127.5) - 1  # rescale to [-1, 1]\n",
    "# print(valid_lr_img.min(), valid_lr_img.max())\n",
    "\n",
    "G2 = get_Gval([1, None, None, 3])\n",
    "G2.load_weights(os.path.join(checkpoint_dir, 'g.h5'))\n",
    "G2.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid_hr_img =(valid_hr_img / 127.5) - 1\n",
    "# valid_hr_img = np.asarray(valid_hr_img, dtype=np.float32)\n",
    "# valid_hr_img = valid_hr_img[np.newaxis,:,:,:]\n",
    "valid_lr_img = valid_lr_img[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid_lr_img = np.asarray(valid_lr_img, dtype=np.float32)\n",
    "size = [valid_lr_img.shape[1], valid_lr_img.shape[2]]\n",
    "\n",
    "output = G2(valid_lr_img).numpy()\n",
    "psnr = tf.image.psnr(output, valid_hr_img, max_val=1.0)\n",
    "print(psnr)\n",
    "ssim2 = tf.image.ssim(output, valid_hr_img, max_val=1.0, filter_size=11,\n",
    "              filter_sigma=1.5, k1=0.01, k2=0.03)\n",
    "print(ssim2)\n",
    "mse = tf.keras.losses.mean_squared_error(output,valid_hr_img).numpy()\n",
    "\n",
    "\n",
    "print(np.sum(mse)/(mse.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37-tf2",
   "language": "python",
   "name": "py37-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}